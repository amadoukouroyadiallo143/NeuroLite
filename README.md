# NeuroLite

Une architecture d'IA lÃ©gÃ¨re pour les appareils mobiles et embarquÃ©s, fournissant des alternatives efficaces aux Transformers. NeuroLite implÃ©mente des approches innovantes (MLP-Mixer, mÃ©moire neuronale, routage adaptatif) pour crÃ©er des modÃ¨les compacts capables de traiter le langage naturel avec une fraction des ressources requises par les architectures traditionnelles.

<div align="center">
<strong>ComplexitÃ© LinÃ©aire | Empreinte Minimale | AGI LÃ©gÃ¨re</strong>
</div>

## ğŸŒŸ Points ClÃ©s

- **Ultra-lÃ©ger**: ModÃ¨les de 1-10Mo, contre 110-340Mo pour les Transformers standards
- **EfficacitÃ© Computationnelle**: ComplexitÃ© linÃ©aire (O(n)) en longueur de sÃ©quence vs quadratique (O(nÂ²)) 
- **MÃ©moire Adaptative**: SystÃ¨me de rÃ©tention contextuelle Ã  long terme inspirÃ© des rÃ©seaux de Hopfield modernes
- **Routage Intelligent**: Activation conditionnelle des experts spÃ©cialisÃ©s selon le type d'entrÃ©e
- **Composant Symbolique**: Module lÃ©ger de raisonnement structurÃ© pour amÃ©liorer les capacitÃ©s symboliques
- **Mobile-First**: ConÃ§u pour fonctionner efficacement sur smartphones, wearables et dispositifs IoT

## ğŸ—ï¸ Architecture

NeuroLite combine plusieurs innovations rÃ©centes en une architecture hybride lÃ©gÃ¨re et performante:

![Architecture NeuroLite](https://placeholder-for-architecture-diagram.com/neurolite_arch.png)

1. **Projection d'entrÃ©e efficace** - Remplace les lourdes tables d'embedding par un encodage lÃ©ger basÃ© sur MinHash et filtres de Bloom (~99% de rÃ©duction de paramÃ¨tres)
2. **Backbone All-MLP** - Couches MLP-Mixer ou HyperMixer pour un traitement de sÃ©quence avec complexitÃ© temporelle et spatiale linÃ©aire
3. **MÃ©moire externe diffÃ©rentiable** - SystÃ¨me de mÃ©moire associative Ã  plusieurs niveaux pour la rÃ©tention contextuelle
4. **Module symbolique** - Composant de raisonnement structurÃ© permettant d'intÃ©grer des connaissances et rÃ¨gles explicites
5. **Routage dynamique** - Activation conditionnelle de sous-modules spÃ©cialisÃ©s via Mixture-of-Experts lÃ©ger

## ğŸ§  Fondements ThÃ©oriques

NeuroLite s'inspire de plusieurs avancÃ©es thÃ©oriques rÃ©centes:

- **MLP-Mixer**: DÃ©montre que des projections linÃ©aires alternÃ©es (token-mixing et channel-mixing) peuvent rivaliser avec l'attention pour de nombreuses tÃ¢ches
- **ComplexitÃ© LinÃ©aire**: Exploite les approches comme Performer, Linformer et FNet qui remplacent l'attention quadratique par des approximations efficaces
- **MÃ©moire Associative Moderne**: IntÃ¨gre des rÃ©seaux de Hopfield continus de grande capacitÃ© pour la mÃ©morisation associative
- **Routage Adaptatif**: Utilise des techniques de routage dynamique pour activer sÃ©lectivement diffÃ©rents "experts" selon le contexte
- **Composants Neurosymboliques**: Combine traitement neuronal et symbolique pour amÃ©liorer les capacitÃ©s de raisonnement avec peu de paramÃ¨tres

## ğŸ“¦ Structure du Projet

```
neurolite/
â”œâ”€â”€ __init__.py        # Point d'entrÃ©e du package
â”œâ”€â”€ config.py          # Configuration des diffÃ©rentes tailles de modÃ¨les
â”œâ”€â”€ model.py           # ModÃ¨le principal et variantes spÃ©cialisÃ©es
â”œâ”€â”€ projection.py      # Couche de projection d'entrÃ©e (MinHash+Bloom)
â”œâ”€â”€ mixer.py           # ImplÃ©mentations MLP-Mixer, HyperMixer, FNet
â”œâ”€â”€ memory.py          # MÃ©moire externe diffÃ©rentiable
â”œâ”€â”€ routing.py         # Routage dynamique et Mixture-of-Experts
â””â”€â”€ symbolic.py        # Composants de raisonnement symbolique

examples/
â”œâ”€â”€ simple_example.py           # Exemple basique d'utilisation
â”œâ”€â”€ classification_example.py   # Classification de texte
â”œâ”€â”€ memory_and_routing_example.py # DÃ©monstration mÃ©moire et routage
â””â”€â”€ benchmark_comparison.py     # Comparaison avec architectures standards

neurolite_demo.py      # Application de dÃ©monstration interactive
```

## ğŸš€ Installation

Pour installer les dÃ©pendances nÃ©cessaires:

```bash
git clone https://github.com/username/NeuroLite.git
cd NeuroLite
pip install -r requirements.txt
```

## ğŸ”§ Utilisation

### Exemple Simple

```python
from neurolite import NeuroLiteModel, NeuroLiteConfig

# CrÃ©er un modÃ¨le ultra-lÃ©ger
config = NeuroLiteConfig.tiny()  # ~1-2Mo
model = NeuroLiteModel(config)

# Traiter du texte
texts = ["NeuroLite est une architecture lÃ©gÃ¨re d'IA."]
outputs = model(input_texts=texts)

# Utiliser les reprÃ©sentations vectorielles (embeddings)
embedding = outputs.mean(dim=1)
```

### Classification de Texte

```python
from neurolite import NeuroLiteForClassification, NeuroLiteConfig

# Configurer un modÃ¨le pour classification
config = NeuroLiteConfig.small()
model = NeuroLiteForClassification(config, num_labels=2)

# InfÃ©rence
outputs = model(input_texts=["Texte Ã  classifier"])
prediction = outputs["logits"].argmax(dim=1)
```

### Utilisation de la MÃ©moire Contextuelle

```python
# CrÃ©er un modÃ¨le avec mÃ©moire
config = NeuroLiteConfig.small()
config.use_external_memory = True
model = NeuroLiteModel(config)

# Fournir du contexte Ã  la mÃ©moire
model(input_texts=["Alice est une ingÃ©nieure vivant Ã  Paris."], update_memory=True)

# La requÃªte suivante sera enrichie par le contexte en mÃ©moire
result = model(input_texts=["OÃ¹ habite-t-elle ?"])
```

## ğŸ§ª Exemples et DÃ©monstration

ExÃ©cutez la dÃ©monstration interactive pour explorer les capacitÃ©s du modÃ¨le:

```bash
python neurolite_demo.py --size tiny  # Options: tiny, small, base
```

Autres exemples disponibles:
- `examples/simple_example.py` - Utilisation de base
- `examples/classification_example.py` - Classification de sentiment
- `examples/memory_and_routing_example.py` - DÃ©monstration mÃ©moire et routage
- `examples/benchmark_comparison.py` - Comparaison avec Transformer

## ğŸ“ˆ Performances

Comparaison avec des architectures standards sur un texte de longueur moyenne (256 tokens):

| Architecture | ParamÃ¨tres | Temps d'infÃ©rence | MÃ©moire (RAM) | ComplexitÃ© |
|--------------|------------|-------------------|---------------|------------|
| BERT-base    | 110M       | ~45ms             | ~440MB        | O(nÂ²)      |
| DistilBERT   | 66M        | ~25ms             | ~265MB        | O(nÂ²)      |
| NeuroLite-base | 8M       | ~10ms             | ~32MB         | O(n)       |
| NeuroLite-small | 3M      | ~5ms              | ~12MB         | O(n)       |
| NeuroLite-tiny  | 1M      | ~2ms              | ~4MB          | O(n)       |

## ğŸ› ï¸ Personnalisation

NeuroLite offre plusieurs configurations prÃ©-dÃ©finies:

```python
# TrÃ¨s lÃ©ger (~1-2Mo)
config = NeuroLiteConfig.tiny()

# LÃ©ger (~5-10Mo)
config = NeuroLiteConfig.small()

# Standard (~20-30Mo)
config = NeuroLiteConfig.base()

# Personnalisation avancÃ©e
config = NeuroLiteConfig(
    hidden_size=256,
    num_mixer_layers=6,
    use_external_memory=True,
    use_dynamic_routing=True,
    use_symbolic_module=True,
    num_experts=4
)
```

## ğŸ“š RÃ©fÃ©rences

Cette implÃ©mentation s'inspire des travaux suivants:
- MLP-Mixer (Tolstikhin et al., 2021)
- pNLP-Mixer (Fusco et al., 2023)
- HyperMixer (Mai et al., 2023)
- FNet (Lee et al., 2022)
- Performer (Choromanski et al., 2020)
- Modern Hopfield Networks (Ramsauer et al., 2020)
- Differentiable Neural Computers (Graves et al., 2016)

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.

## ğŸ¤ Contributions

Les contributions sont bienvenues! N'hÃ©sitez pas Ã  soumettre des pull requests ou Ã  ouvrir des issues pour des suggestions d'amÃ©lioration.

---

<div align="center">
<strong>NeuroLite - Vers une AGI lÃ©gÃ¨re et efficiente</strong>
</div>
