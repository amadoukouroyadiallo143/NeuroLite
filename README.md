# NeuroLite

Une architecture d'IA lÃ©gÃ¨re pour les appareils mobiles et embarquÃ©s, fournissant des alternatives efficaces aux Transformers. NeuroLite implÃ©mente des approches innovantes (MLP-Mixer, mÃ©moire neuronale, routage adaptatif) pour crÃ©er des modÃ¨les compacts capables de traiter le langage naturel avec une fraction des ressources requises par les architectures traditionnelles.

<div align="center">
<strong>ComplexitÃ© LinÃ©aire | Empreinte Minimale | AGI LÃ©gÃ¨re</strong>
</div>

## ğŸŒŸ Points ClÃ©s

- **Ultra-lÃ©ger**: ModÃ¨les de 1-10Mo, contre 110-340Mo pour les Transformers standards
- **EfficacitÃ© Computationnelle**: ComplexitÃ© linÃ©aire (O(n)) en longueur de sÃ©quence vs quadratique (O(nÂ²)) 
- **MÃ©moire Adaptative**: SystÃ¨me de rÃ©tention contextuelle Ã  long terme inspirÃ© des rÃ©seaux de Hopfield modernes
- **Routage Intelligent**: Activation conditionnelle des experts spÃ©cialisÃ©s selon le type d'entrÃ©e
- **Composant Symbolique**: Module lÃ©ger de raisonnement structurÃ© pour amÃ©liorer les capacitÃ©s symboliques
- **Mobile-First**: ConÃ§u pour fonctionner efficacement sur smartphones, wearables et dispositifs IoT

## ğŸ—ï¸ Architecture

NeuroLite combine plusieurs innovations rÃ©centes en une architecture hybride lÃ©gÃ¨re et performante:

![Architecture NeuroLite](https://placeholder-for-architecture-diagram.com/neurolite_arch.png)

1. **Projection d'entrÃ©e efficace** - Remplace les lourdes tables d'embedding par un encodage lÃ©ger basÃ© sur MinHash et filtres de Bloom (~99% de rÃ©duction de paramÃ¨tres)
2. **Backbone All-MLP** - Couches MLP-Mixer ou HyperMixer pour un traitement de sÃ©quence avec complexitÃ© temporelle et spatiale linÃ©aire
3. **MÃ©moire externe diffÃ©rentiable** - SystÃ¨me de mÃ©moire associative Ã  plusieurs niveaux pour la rÃ©tention contextuelle
4. **Module symbolique** - Composant de raisonnement structurÃ© permettant d'intÃ©grer des connaissances et rÃ¨gles explicites
5. **Routage dynamique** - Activation conditionnelle de sous-modules spÃ©cialisÃ©s via Mixture-of-Experts lÃ©ger

## ğŸ§  Fondements ThÃ©oriques

NeuroLite s'inspire de plusieurs avancÃ©es thÃ©oriques rÃ©centes:

- **MLP-Mixer**: DÃ©montre que des projections linÃ©aires alternÃ©es (token-mixing et channel-mixing) peuvent rivaliser avec l'attention pour de nombreuses tÃ¢ches
- **ComplexitÃ© LinÃ©aire**: Exploite les approches comme Performer, Linformer et FNet qui remplacent l'attention quadratique par des approximations efficaces
- **MÃ©moire Associative Moderne**: IntÃ¨gre des rÃ©seaux de Hopfield continus de grande capacitÃ© pour la mÃ©morisation associative
- **Routage Adaptatif**: Utilise des techniques de routage dynamique pour activer sÃ©lectivement diffÃ©rents "experts" selon le contexte
- **Composants Neurosymboliques**: Combine traitement neuronal et symbolique pour amÃ©liorer les capacitÃ©s de raisonnement avec peu de paramÃ¨tres

## ğŸ“¦ Structure du Projet

```
neurolite/
â”œâ”€â”€ __init__.py        # Point d'entrÃ©e du package
â”œâ”€â”€ config.py          # Configuration des diffÃ©rentes tailles de modÃ¨les
â”œâ”€â”€ model.py           # ModÃ¨le principal et variantes spÃ©cialisÃ©es
â”œâ”€â”€ projection.py      # Couche de projection d'entrÃ©e (MinHash+Bloom)
â”œâ”€â”€ mixer.py           # ImplÃ©mentations MLP-Mixer, HyperMixer, FNet
â”œâ”€â”€ memory.py          # MÃ©moire externe diffÃ©rentiable
â”œâ”€â”€ routing.py         # Routage dynamique et Mixture-of-Experts
â””â”€â”€ symbolic.py        # Composants de raisonnement symbolique

training/
â”œâ”€â”€ data_manager.py    # Gestion des donnÃ©es d'entraÃ®nement et validation
â”œâ”€â”€ train_generator.py # Script d'entraÃ®nement du modÃ¨le de gÃ©nÃ©ration
â””â”€â”€ train_classifier.py # Script d'entraÃ®nement du classifieur

data/
â””â”€â”€ wikitext/         # DonnÃ©es d'entraÃ®nement provenant du corpus WikiText
    â”œâ”€â”€ train/        # DonnÃ©es d'entraÃ®nement
    â”œâ”€â”€ val/          # DonnÃ©es de validation
    â””â”€â”€ test/         # DonnÃ©es de test

examples/
â”œâ”€â”€ simple_example.py           # Exemple basique d'utilisation
â”œâ”€â”€ classification_example.py   # Classification de texte
â”œâ”€â”€ memory_and_routing_example.py # DÃ©monstration mÃ©moire et routage
â””â”€â”€ benchmark_comparison.py     # Comparaison avec architectures standards

generate_text.py     # Utilitaire de gÃ©nÃ©ration de texte avec modÃ¨le entraÃ®nÃ©
neurolite_demo.py    # Application de dÃ©monstration interactive
```

## ğŸš€ Installation

Pour installer les dÃ©pendances nÃ©cessaires:

```bash
git clone https://github.com/username/NeuroLite.git
cd NeuroLite
python -m venv .venv
.venv\Scripts\activate  # Sur Windows
source .venv/bin/activate  # Sur Linux/MacOS
pip install -r requirements.txt
```

## ğŸ”§ Utilisation

### Exemple Simple

```python
from neurolite import NeuroLiteModel, NeuroLiteConfig

# CrÃ©er un modÃ¨le ultra-lÃ©ger
config = NeuroLiteConfig.tiny()  # ~1-2Mo
model = NeuroLiteModel(config)

# Traiter du texte
texts = ["NeuroLite est une architecture lÃ©gÃ¨re d'IA."]
outputs = model(input_texts=texts)

# Utiliser les reprÃ©sentations vectorielles (embeddings)
embedding = outputs.mean(dim=1)
```

### Classification de Texte

```python
from neurolite import NeuroLiteForClassification, NeuroLiteConfig

# Configurer un modÃ¨le pour classification
config = NeuroLiteConfig.small()
model = NeuroLiteForClassification(config, num_labels=2)

# InfÃ©rence
outputs = model(input_texts=["Texte Ã  classifier"])
prediction = outputs["logits"].argmax(dim=1)
```

### Utilisation de la MÃ©moire Contextuelle

```python
# CrÃ©er un modÃ¨le avec mÃ©moire
config = NeuroLiteConfig.small()
config.use_external_memory = True
model = NeuroLiteModel(config)

# Fournir du contexte Ã  la mÃ©moire
model(input_texts=["Alice est une ingÃ©nieure vivant Ã  Paris."], update_memory=True)

# La requÃªte suivante sera enrichie par le contexte en mÃ©moire
result = model(input_texts=["OÃ¹ habite-t-elle ?"])
```

## ğŸ‹ï¸ EntraÃ®nement du ModÃ¨le

NeuroLite comprend des scripts d'entraÃ®nement robustes pour diverses tÃ¢ches. Pour entraÃ®ner un modÃ¨le de gÃ©nÃ©ration de texte sur le corpus WikiText :

```bash
python training/train_generator.py --data_dir "data/wikitext" --batch_size 32 --seq_length 512 --vocab_size 32000 --num_epochs 20
```

Options d'entraÃ®nement importantes :
- `--batch_size` : Taille des batchs (dÃ©faut: 32)
- `--seq_length` : Longueur de sÃ©quence pour l'entraÃ®nement (dÃ©faut: 128)
- `--vocab_size` : Taille du vocabulaire (dÃ©faut: 10000)
- `--hidden_size` : Dimension des couches cachÃ©es (dÃ©faut: 256)
- `--num_layers` : Nombre de couches mixer (dÃ©faut: 6)
- `--use_memory` : Activer la mÃ©moire externe (flag)
- `--learning_rate` : Taux d'apprentissage (dÃ©faut: 5e-5)
- `--max_samples` : Limite le nombre d'Ã©chantillons (pour tests rapides)

Pour entraÃ®ner sur un matÃ©riel limitÃ©, utilisez des paramÃ¨tres plus lÃ©gers :

```bash
python training/train_generator.py --data_dir "data/wikitext" --batch_size 8 --seq_length 128 --hidden_size 128 --num_layers 4 --num_epochs 5 --max_samples 1000
```

Une fois entraÃ®nÃ©, gÃ©nÃ©rez du texte avec le modÃ¨le :

```bash
python generate_text.py --model_path "models/generator_ep20.pt" --prompt "NeuroLite est" --max_length 100
```

## ğŸ§ª Exemples et DÃ©monstration

ExÃ©cutez la dÃ©monstration interactive pour explorer les capacitÃ©s du modÃ¨le:

```bash
python neurolite_demo.py --size tiny  # Options: tiny, small, base
```

Autres exemples disponibles:
- `examples/simple_example.py` - Utilisation de base
- `examples/classification_example.py` - Classification de sentiment
- `examples/memory_and_routing_example.py` - DÃ©monstration mÃ©moire et routage
- `examples/benchmark_comparison.py` - Comparaison avec Transformer

## ğŸ“ˆ Performances

Comparaison avec des architectures standards sur un texte de longueur moyenne (256 tokens):

| Architecture | ParamÃ¨tres | Temps d'infÃ©rence | MÃ©moire (RAM) | ComplexitÃ© |
|--------------|------------|-------------------|---------------|------------|
| BERT-base    | 110M       | ~45ms             | ~440MB        | O(nÂ²)      |
| DistilBERT   | 66M        | ~25ms             | ~265MB        | O(nÂ²)      |
| NeuroLite-base | 8M       | ~10ms             | ~32MB         | O(n)       |
| NeuroLite-small | 3M      | ~5ms              | ~12MB         | O(n)       |
| NeuroLite-tiny  | 1M      | ~2ms              | ~4MB          | O(n)       |

## ğŸ› ï¸ Personnalisation

NeuroLite offre plusieurs configurations prÃ©-dÃ©finies:

```python
# TrÃ¨s lÃ©ger (~1-2Mo)
config = NeuroLiteConfig.tiny()

# LÃ©ger (~5-10Mo)
config = NeuroLiteConfig.small()

# Standard (~20-30Mo)
config = NeuroLiteConfig.base()

# Personnalisation avancÃ©e
config = NeuroLiteConfig(
    hidden_size=256,
    num_mixer_layers=6,
    use_external_memory=True,
    use_dynamic_routing=True,
    use_symbolic_module=True,
    num_experts=4
)
```

## ğŸ”„ Gestion des DonnÃ©es & Optimisations

NeuroLite comprend des systÃ¨mes robustes pour la gestion et le traitement des donnÃ©es :

- **WikiTextDataset** : Chargement efficace et gestion du corpus WikiText
- **Padding intelligent** : Traitement optimal des textes plus courts que la longueur de sÃ©quence cible
- **Tokenization optimisÃ©e** : Tokenizer rapide avec vocabulaire ajustable (jusqu'Ã  32K tokens)
- **Multiprocessing** : Chargement parallÃ¨le des donnÃ©es pour accÃ©lÃ©rer l'entraÃ®nement
- **Gestion de batch dynamique** : Fonction de collation robuste pour la crÃ©ation de batchs homogÃ¨nes
- **IntÃ©gration PyTorch** : CompatibilitÃ© complÃ¨te avec l'Ã©cosystÃ¨me PyTorch (DataLoader, etc.)

Chaque composant est conÃ§u pour Ãªtre efficace en mÃ©moire et en temps de calcul, mÃªme sur du matÃ©riel limitÃ©.

## ğŸ“š RÃ©fÃ©rences

Cette implÃ©mentation s'inspire des travaux suivants:
- MLP-Mixer (Tolstikhin et al., 2021)
- pNLP-Mixer (Fusco et al., 2023)
- HyperMixer (Mai et al., 2023)
- FNet (Lee et al., 2022)
- Performer (Choromanski et al., 2020)
- Modern Hopfield Networks (Ramsauer et al., 2020)
- Differentiable Neural Computers (Graves et al., 2016)
- State Space Models (Gu et al., 2023)
- Mamba (Gu et al., 2023)

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.

## ğŸ¤ Contributions

Les contributions sont bienvenues! N'hÃ©sitez pas Ã  soumettre des pull requests ou Ã  ouvrir des issues pour des suggestions d'amÃ©lioration.

---

<div align="center">
<strong>NeuroLite - Vers une AGI lÃ©gÃ¨re et efficiente</strong>
</div>
