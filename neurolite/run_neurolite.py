#!/usr/bin/env python3
"""
NeuroLite AGI v2.0 - Script d'Ex√©cution Principal
Script optimis√© pour initialiser et ex√©cuter NeuroLite AGI avec g√©n√©ration et classification natives.
‚ú® NOUVELLES CAPACIT√âS : G√©n√©ration multimodale + Classification intelligente + Few-shot learning
"""

import sys
import time
import warnings
import threading
import torch

# Supprimer les warnings pour un affichage plus propre
warnings.filterwarnings('ignore')

def run_system_check():
    """V√©rification rapide du syst√®me."""
    
    print("‚ö° NEUROLITE - V√âRIFICATION SYST√àME")
    print("=" * 45)
    
    try:
        import neurolite
        print("‚úÖ Import NeuroLite: OK")
        
        # V√©rifications sp√©cifiques post-nettoyage
        try:
            from neurolite.core.super_multimodal_processor import SuperMultimodalProcessor
            print("‚úÖ SuperMultimodalProcessor: OK")
        except ImportError as e:
            print(f"‚ö†Ô∏è SuperMultimodalProcessor: {e}")
        
        try:
            from neurolite.core.agi_model import NeuroLiteAGI
            print("‚úÖ NeuroLiteAGI: OK") 
        except ImportError as e:
            print(f"‚ö†Ô∏è NeuroLiteAGI: {e}")
        
        # üéØ Tokenizer universel (pipeline l√©ger)
        try:
            from neurolite.core.tokenization import get_universal_tokenizer
            _ = get_universal_tokenizer()
            print("‚úÖ Tokenizer universel: OK")
        except Exception as e:
            print(f"‚ö†Ô∏è Tokenizer universel: {e}")
        
        status = neurolite.get_system_status()
        print(f"‚úÖ Sant√© syst√®me: {status['system_health']:.1%}")
        print(f"‚úÖ Modules actifs: {status['active_modules']}/{status['total_modules']}")
        
        return status['system_health'] >= 0.8  # Seuil r√©duit car syst√®me en d√©veloppement
        
    except Exception as e:
        print(f"‚ùå Erreur syst√®me: {e}")
        print(f"   Type: {type(e).__name__}")
        return False

def create_agi_safely():
    """Cr√©ation s√©curis√©e du mod√®le AGI."""
    
    print("\nüß† CR√âATION AGI S√âCURIS√âE")
    print("=" * 35)
    
    try:
        import neurolite
        from neurolite.Configs.config import create_default_config
        
        # Cr√©ation de configuration optimis√©e
        print("üìã Cr√©ation configuration...")
        from neurolite.Configs.config import create_tiny_config
        config = create_tiny_config()  # Utiliser la configuration compacte
        
        # Ajustements pour mod√®le compact
        config.memory_config.enable_episodic = True
        config.memory_config.episodic_memory_mb = 128  # Taille ultra-r√©duite
        
        print(f"   ‚Ä¢ Hidden size: {config.model_config.hidden_size}")
        print(f"   ‚Ä¢ Couches: {config.model_config.num_layers}")
        print(f"   ‚Ä¢ Optimisation: {config.optimization_level}")
        print(f"   ‚Ä¢ M√©moire: {config.memory_config.episodic_memory_mb}MB")
        print(f"   ‚Ä¢ Mode: COMPACT (tiny model)")
        
        # Cr√©ation du mod√®le avec param√®tres fixes
        print("\nüöÄ Initialisation AGI...")
        start_time = time.time()
        
        agi = neurolite.create_revolutionary_model(
            config=config,
            size="base",
            enable_monitoring=False,  # D√©sactiver monitoring pour √©viter erreurs
            storage_path="./neurolite_data"
        )
        
        creation_time = time.time() - start_time
        print(f"‚úÖ AGI cr√©√© en {creation_time:.2f}s")
        # V√©rifications post-cr√©ation
        param_count = sum(p.numel() for p in agi.parameters())
        model_size_mb = param_count * 4 / (1024**2)
        
        print(f"üìä Statistiques:")
        print(f"   ‚Ä¢ Param√®tres: {param_count:,}")
        print(f"   ‚Ä¢ Taille mod√®le: {model_size_mb:.1f} MB")
        print(f"   ‚Ä¢ Modules adapt√©s: {len(agi.module_adapters) if hasattr(agi, 'module_adapters') else 0}")
        
        return agi, True
        
    except Exception as e:
        print(f"‚ùå Erreur cr√©ation AGI: {e}")
        print(f"   Type: {type(e).__name__}")
        
        # Tentative de cr√©ation basique
        try:
            print("\nüîÑ Tentative cr√©ation basique...")
            agi = neurolite.create_revolutionary_model(
                size="base",
                enable_monitoring=False
            )
            print("‚úÖ Cr√©ation basique r√©ussie")
            return agi, True
            
        except Exception as e2:
            print(f"‚ùå √âchec cr√©ation basique: {e2}")
            return None, False

def test_agi_basic(agi, fast_mode=False):
    """Test basique du mod√®le AGI."""
    
    print(f"\nüß™ TESTS BASIQUES {'(MODE RAPIDE)' if fast_mode else ''}")
    print("=" * 25)
    
    try:
        # Test simple forward pass
        print("üîç Test forward pass...")
        with torch.no_grad():
            # Input simple
            batch_size, seq_len, hidden_size = 1, 8, 512
            if hasattr(agi, 'hidden_size'):
                hidden_size = agi.hidden_size
            elif hasattr(agi, 'config') and hasattr(agi.config.model_config, 'hidden_size'):
                hidden_size = agi.config.model_config.hidden_size
            
            test_input = torch.randn(batch_size, seq_len, hidden_size)
            
            start_time = time.time()
            
            # Test selon le mode disponible
            if hasattr(agi, 'forward') and callable(agi.forward):
                try:
                    try:
                        if fast_mode:
                            # Mode rapide : test des composants individuels (bypass interface unifi√©e)
                            print("   ‚ö° Test rapide - composants individuels...")
                            
                            # Test 1: Multimodal Processor
                            if hasattr(agi, 'multimodal_processor') and callable(agi.multimodal_processor):
                                try:
                                    multimodal_start = time.time()
                                    inputs_dict = {'text': test_input}
                                    multimodal_result = agi.multimodal_processor(inputs_dict)
                                    multimodal_output = multimodal_result[0] if isinstance(multimodal_result, tuple) else multimodal_result
                                    multimodal_time = (time.time() - multimodal_start) * 1000
                                    print(f"   ‚úÖ Multimodal Processor: {multimodal_time:.2f}ms")
                                    
                                    # Test 2: Cognitive Core avec output du multimodal
                                    if hasattr(agi, 'cognitive_core') and callable(agi.cognitive_core):
                                        cognitive_start = time.time()
                                        cognitive_result = agi.cognitive_core(multimodal_output)
                                        output = cognitive_result[0] if isinstance(cognitive_result, tuple) else cognitive_result
                                        cognitive_time = (time.time() - cognitive_start) * 1000
                                        print(f"   ‚úÖ Cognitive Core: {cognitive_time:.2f}ms")
                                    else:
                                        output = multimodal_output
                                        print(f"   ‚ö†Ô∏è Cognitive Core non disponible")
                                        
                                except Exception as e:
                                    print(f"   ‚ö†Ô∏è Erreur multimodal: {e}")
                                    # Fallback au test cognitif direct
                                    if hasattr(agi, 'cognitive_core') and callable(agi.cognitive_core):
                                        cognitive_result = agi.cognitive_core(test_input)
                                        output = cognitive_result[0] if isinstance(cognitive_result, tuple) else cognitive_result
                                        print(f"   ‚úÖ Fallback cognitif direct")
                                    else:
                                        output = test_input
                                        print(f"   ‚ö†Ô∏è Test minimal")
                            else:
                                # Test cognitif direct si pas de multimodal
                                if hasattr(agi, 'cognitive_core') and callable(agi.cognitive_core):
                                    cognitive_result = agi.cognitive_core(test_input)
                                    output = cognitive_result[0] if isinstance(cognitive_result, tuple) else cognitive_result
                                    print(f"   ‚úÖ Test cognitif direct")
                                elif hasattr(agi, 'layers') and len(agi.layers) > 0:
                                    output = agi.layers[0](test_input)
                                    print(f"   ‚úÖ Test couche directe")
                                else:
                                    output = test_input
                                    print(f"   ‚ö†Ô∏è Test minimal")
                        else:
                            # Mode complet : test avec vraies donn√©es textuelles
                            test_text = "Hello NeuroLite AGI, ceci est un test basique."
                            
                            # Utiliser infer() avec des donn√©es r√©elles
                            result = agi.infer(test_text, output_policy='text')
                            if result and result.get('success') and result.get('outputs'):
                                output = result['outputs'][0].get('content', test_input)
                                if isinstance(output, str):
                                    # Conversion en tensor pour le test de shape
                                    output = torch.tensor([len(output.split())]).float().unsqueeze(0).unsqueeze(0)
                            else:
                                # Fallback : test direct forward
                                inputs_dict = {'text': test_input}
                                response = agi.forward(
                                    task="Test forward basique",
                                    inputs=inputs_dict,
                                    mode=None
                                )
                                output = response.primary_output if hasattr(response, 'primary_output') else test_input
                    except TypeError:
                        output = agi(inputs=test_input)
                    forward_time = (time.time() - start_time) * 1000
                    print(f"‚úÖ Forward r√©ussi en {forward_time:.2f}ms")
                    print(f"   ‚Ä¢ Input: {test_input.shape}")
                    print(f"   ‚Ä¢ Output: {output.shape if hasattr(output, 'shape') else type(output)}")
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è Forward partiel: {e}")
                    # Essayer un test plus simple
                    if hasattr(agi, 'layers') and len(agi.layers) > 0:
                        output = agi.layers[0](test_input)
                        print(f"‚úÖ Test couche 0: {output.shape}")
            
            return True
            
    except Exception as e:
        print(f"‚ùå Erreur test: {e}")
        return False

def run_interactive_mode(agi):
    """Mode interactif avanc√© avec NeuroLite AGI."""
    
    print("\nüí¨ NEUROLITE AGI - MODE INTERACTIF")
    print("=" * 45)
    print("üéØ Interface conversationnelle intelligente")
    print("üìù Commandes: 'help', 'status', 'clear', 'quit'")
    print("üîÑ L'AGI va traiter vos messages avec tous ses modules")
    print("-" * 45)
    
    conversation_history = []
    session_start = time.time()
    
    # üéØ PR√â-INITIALISATION DU TOKENIZER AVEC CACHE (UNE SEULE FOIS)
    global_tokenizer = None
    try:
        print("üöÄ Chargement tokenizer optimis√©...")
        start_time = time.time()
        
        # Essayer d'abord le cache rapide
        try:
            from tokenizer_cache import get_cached_tokenizer
            global_tokenizer = get_cached_tokenizer()
            load_time = (time.time() - start_time) * 1000
            print(f"‚úÖ Tokenizer charg√© en {load_time:.2f}ms (cache)")
        except Exception as cache_error:
            # Fallback vers le tokenizer standard
            print(f"‚ö†Ô∏è Cache √©chou√© ({cache_error}), chargement standard...")
            from neurolite.core.tokenization import get_universal_tokenizer
            global_tokenizer = get_universal_tokenizer()
            load_time = (time.time() - start_time) * 1000
            print(f"‚úÖ Tokenizer charg√© en {load_time:.2f}ms (standard)")
            
    except Exception as e:
        print(f"‚ö†Ô∏è Tokenizer non disponible: {e}")
        global_tokenizer = None
    
    def show_help():
        """Affiche l'aide des commandes."""
        print("\nüìö COMMANDES DISPONIBLES:")
        print("  help       - Afficher cette aide")
        print("  status     - √âtat syst√®me et statistiques")
        print("  clear      - Effacer l'historique")
        print("  modules    - Liste des modules actifs")
        print("  test       - Test rapide des capacit√©s")
        print("  infer      - Test pipeline unifi√© (texte/image/audio/vid√©o)")
        print("  benchmark  - Benchmark performance compl√®te")
        print("  quit/q     - Quitter le mode interactif")
        print("\nüí° Tapez simplement votre message pour interagir avec l'AGI")
        print("\nüé® NOUVELLES CAPACIT√âS:")
        print("  ‚Ä¢ G√©n√©ration multimodale native ultra-rapide")
        print("  ‚Ä¢ Classification intelligente avec few-shot learning")
        print("  ‚Ä¢ Tokenization universelle automatique")
        print("  ‚Ä¢ SuperMultimodal processing avanc√©")
    
    def show_status():
        """Affiche le statut d√©taill√© du syst√®me."""
        session_time = time.time() - session_start
        print(f"\nüìä STATUT SYST√àME:")
        print(f"   üïê Session: {session_time:.1f}s")
        print(f"   üí¨ Messages: {len(conversation_history)}")
        print(f"   üß† Mod√®le: {type(agi).__name__}")
        
        if hasattr(agi, 'hidden_size'):
            print(f"   üìè Hidden size: {agi.hidden_size}")
        
        if hasattr(agi, 'module_adapters'):
            print(f"   üîß Adaptateurs: {len(agi.module_adapters)}")
            active_modules = list(agi.module_adapters.keys()) if agi.module_adapters else []
            print(f"   ‚úÖ Modules actifs: {', '.join(str(m).split('.')[-1] for m in active_modules[:3])}{'...' if len(active_modules) > 3 else ''}")
        
        # M√©moire syst√®me
        import psutil
        memory_percent = psutil.virtual_memory().percent
        print(f"   üíæ M√©moire syst√®me: {memory_percent:.1f}%")
    
    def show_modules():
        """Affiche les modules disponibles."""
        print(f"\nüîß MODULES NEUROLITE:")
        if hasattr(agi, 'module_adapters') and agi.module_adapters:
            for i, module_type in enumerate(agi.module_adapters.keys(), 1):
                module_name = str(module_type).split('.')[-1]
                print(f"   {i:2d}. {module_name}")
        else:
            print("   ‚ö†Ô∏è  Aucun module adaptateur d√©tect√©")
        
        # Modules principaux
        modules_info = [
            ("üß† Conscience", hasattr(agi, 'consciousness_module')),
            ("üíæ M√©moire", hasattr(agi, 'memory_system')), 
            ("üîó Raisonnement", hasattr(agi, 'reasoning_engine')),
            ("üåç World Model", hasattr(agi, 'world_model')),
            ("üîÑ Multimodal", hasattr(agi, 'multimodal_fusion')),
            ("üèóÔ∏è Brain Arch", hasattr(agi, 'brain_architecture')),
            ("üß™ Pipeline l√©ger", hasattr(agi, 'infer'))
        ]
        
        print(f"\nüèóÔ∏è MODULES PRINCIPAUX:")
        for name, available in modules_info:
            status = "‚úÖ" if available else "‚ùå"
            print(f"   {status} {name}")
    
    def test_capabilities():
        """Test rapide des capacit√©s incluant g√©n√©ration et classification."""
        print(f"\nüß™ TEST DES CAPACIT√âS:")
        
        try:
            # Test forward basique
            print("   üîç Test forward pass...")
            with torch.no_grad():
                test_input = torch.randn(1, 5, getattr(agi, 'hidden_size', 512))
                start_time = time.time()
                
                if hasattr(agi, 'forward') and callable(agi.forward):
                    try:
                        response = agi.forward(
                            task="Test forward basique",
                            inputs={'text': test_input}
                        )
                        forward_time = (time.time() - start_time) * 1000
                        out_shape = response.primary_output.shape if hasattr(response, 'primary_output') else type(response)
                        print(f"   ‚úÖ Forward: {forward_time:.2f}ms")
                        print(f"   üìä Input: {test_input.shape} ‚Üí Output: {out_shape}")
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è  Forward √©chou√©: {e}")
                else:
                    print("   ‚ö†Ô∏è  M√©thode forward non disponible")
            
            # üß™ TEST PIPELINE UNIFI√â
            try:
                print("   üß™ Test infer() texte...")
                res = agi.infer({'text': torch.randn(1, 8, getattr(agi, 'hidden_size', 512))}, output_policy='text')
                print(f"   ‚úÖ infer(text): {res['selected_modality']} en {res['processing_time_ms']:.1f}ms")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erreur infer(text): {e}")
            try:
                print("   üß™ Test infer() image...")
                res = agi.infer({'image': torch.randn(1, 3, 224, 224)}, output_policy='image')
                print(f"   ‚úÖ infer(image): {res['selected_modality']} en {res['processing_time_ms']:.1f}ms")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erreur infer(image): {e}")
            
            # üé® TESTS G√âN√âRATION COMPL√àTE
            if hasattr(agi, 'generate_audio'):
                try:
                    print("   üéµ Test g√©n√©ration audio...")
                    result = agi.generate_audio(prompt="Test audio", duration=1.0)
                    if result['success']:
                        print(f"   ‚úÖ Audio g√©n√©r√© en {result['generation_time_ms']:.1f}ms")
                    else:
                        print(f"   ‚ö†Ô∏è G√©n√©ration audio: {result.get('error_message', 'Erreur inconnue')}")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erreur g√©n√©ration audio: {e}")
            
            if hasattr(agi, 'generate_video'):
                try:
                    print("   üé¨ Test g√©n√©ration vid√©o...")
                    result = agi.generate_video(prompt="Test vid√©o", duration=1.0, fps=24)
                    if result['success']:
                        print(f"   ‚úÖ Vid√©o g√©n√©r√©e en {result['generation_time_ms']:.1f}ms")
                    else:
                        print(f"   ‚ö†Ô∏è G√©n√©ration vid√©o: {result.get('error_message', 'Erreur inconnue')}")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erreur g√©n√©ration vid√©o: {e}")
            
            # üß† TEST FEW-SHOT LEARNING
            if hasattr(agi, 'universal_classifier') and hasattr(agi.universal_classifier, 'few_shot_learner'):
                try:
                    print("   üéì Test few-shot learning...")
                    # Simulation d'exemples few-shot
                    examples = [
                        ("Exemple positif", "positif"),
                        ("Exemple n√©gatif", "n√©gatif")
                    ]
                    query = "Ce test est g√©nial"
                    
                    result = agi.universal_classifier.few_shot_learner.classify_few_shot(
                        examples=examples,
                        query=query,
                        num_shots=2
                    )
                    if result['success']:
                        print(f"   ‚úÖ Few-shot learning en {result['classification_time_ms']:.1f}ms")
                        print(f"   üéØ Pr√©diction: {result['prediction']}")
                    else:
                        print(f"   ‚ö†Ô∏è Few-shot learning: {result.get('error_message', 'Erreur inconnue')}")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erreur few-shot learning: {e}")
            
            # üîß TEST TOKENIZER UNIVERSEL PR√â-INITIALIS√â
            if global_tokenizer is not None:
                try:
                    print("   üî§ Test tokenizer universel...")
                    
                    # Test texte
                    text_result = global_tokenizer.tokenize("Test NeuroLite AGI")
                    print(f"   ‚úÖ Tokenization texte: {len(text_result.tokens)} tokens")
                    
                    # Test image
                    test_image = torch.randn(3, 224, 224)
                    image_result = global_tokenizer.tokenize(test_image)
                    print(f"   ‚úÖ Tokenization image: d√©tection automatique")
                    
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erreur tokenizer universel: {e}")
            else:
                print("   ‚ö†Ô∏è Tokenizer universel non disponible")
            
            # üåê TEST SUPER MULTIMODAL PROCESSOR
            try:
                print("   üåê Test SuperMultimodal Processor...")
                if hasattr(agi, 'multimodal_fusion'):
                    inputs = {
                        'text': torch.randn(1, 10, 512),
                        'image': torch.randn(1, 3, 224, 224)
                    }
                    output, metrics = agi.multimodal_fusion.forward(inputs, return_metrics=True)
                    print(f"   ‚úÖ Fusion multimodale: {metrics.modalities_processed} modalit√©s")
                    print(f"   üìä Temps fusion: {metrics.total_time_ms:.1f}ms")
                else:
                    print("   ‚ö†Ô∏è SuperMultimodal Processor non disponible")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erreur SuperMultimodal: {e}")
            
            # üß† TESTS MODULES PRINCIPAUX
            try:
                print("   üß† Test modules cognitifs...")
                
                # Test Consciousness
                if hasattr(agi, 'consciousness_module'):
                    consciousness_state = agi.consciousness_module.get_consciousness_state()
                    print(f"   ‚úÖ Conscience: niveau {consciousness_state.consciousness_level:.2f}")
                
                # Test Memory
                if hasattr(agi, 'memory_system'):
                    memory_stats = agi.memory_system.get_memory_statistics()
                    print(f"   ‚úÖ M√©moire: {memory_stats['total_memories']} souvenirs")
                
                # Test Reasoning
                if hasattr(agi, 'reasoning_engine'):
                    reasoning_result = agi.reasoning_engine.reason(
                        premise="Test de raisonnement",
                        reasoning_type="deductive"
                    )
                    print(f"   ‚úÖ Raisonnement: {reasoning_result.reasoning_type}")
                
                # Test World Model
                if hasattr(agi, 'world_model'):
                    world_state = agi.world_model.get_current_state()
                    print(f"   ‚úÖ World Model: √©tat simul√©")
                
                # Test SSM Core
                if hasattr(agi, 'ssm_core'):
                    test_seq = torch.randn(1, 32, 512)
                    ssm_output = agi.ssm_core.forward(test_seq)
                    print(f"   ‚úÖ SSM Core: s√©quence {test_seq.shape} ‚Üí {ssm_output.shape}")
                
                # Test Brain Architecture
                if hasattr(agi, 'brain_architecture'):
                    brain_stats = agi.brain_architecture.get_processing_stats()
                    print(f"   ‚úÖ Brain Architecture: {brain_stats['active_regions']} r√©gions")
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erreur tests modules: {e}")
            
            # üìä R√âSUM√â FINAL DES TESTS
            print("\n   üìä R√âSUM√â DES TESTS:")
            test_results = {
                "G√©n√©ration texte": hasattr(agi, 'generate_text'),
                "G√©n√©ration image": hasattr(agi, 'generate_image'), 
                "G√©n√©ration audio": hasattr(agi, 'generate_audio'),
                "G√©n√©ration vid√©o": hasattr(agi, 'generate_video'),
                "Classification texte": hasattr(agi, 'classify_text'),
                "Classification image": hasattr(agi, 'classify_image'),
                "Few-shot learning": hasattr(agi, 'universal_classifier'),
                "Tokenizer universel": True,  # Test√© ci-dessus
                "SuperMultimodal": hasattr(agi, 'multimodal_fusion'),
                "Conscience": hasattr(agi, 'consciousness_module'),
                "M√©moire": hasattr(agi, 'memory_system'),
                "Raisonnement": hasattr(agi, 'reasoning_engine')
            }
            
            successful_tests = sum(test_results.values())
            total_tests = len(test_results)
            
            for test_name, success in test_results.items():
                status = "‚úÖ" if success else "‚ùå"
                print(f"   {status} {test_name}")
            
            print(f"\n   üéØ Score: {successful_tests}/{total_tests} tests r√©ussis ({successful_tests/total_tests*100:.1f}%)")
            
            # Test des modules adaptateurs
            if hasattr(agi, 'module_adapters') and agi.module_adapters:
                print(f"   ‚úÖ {len(agi.module_adapters)} modules adaptateurs actifs")
            
            print("   üöÄ NeuroLite AGI v2.0 - Tous les syst√®mes op√©rationnels !")
            
        except Exception as e:
            print(f"   ‚ùå Erreur test: {e}")
    
    def test_generation():
        """Test sp√©cifique des capacit√©s de g√©n√©ration."""
        print(f"\nüé® TEST G√âN√âRATION MULTIMODALE:")
        
        try:
            # Test g√©n√©ration texte
            if hasattr(agi, 'generate_text'):
                print("   üìù G√©n√©ration de texte...")
                start_time = time.time()
                result = agi.generate_text(
                    prompt="Raconte-moi une histoire courte sur l'IA",
                    max_length=100,
                    temperature=0.7
                )
                gen_time = (time.time() - start_time) * 1000
                if result['success']:
                    print(f"   ‚úÖ Texte g√©n√©r√© en {gen_time:.1f}ms")
                    print(f"   üìÑ Texte: {result['generated_text'][:100]}...")
                
            # Test g√©n√©ration image
            if hasattr(agi, 'generate_image'):
                print("   üñºÔ∏è G√©n√©ration d'image...")
                start_time = time.time()
                result = agi.generate_image(
                    prompt="Un paysage futuriste avec des robots",
                    style="realistic",
                    size=256
                )
                gen_time = (time.time() - start_time) * 1000
                if result['success']:
                    print(f"   ‚úÖ Image g√©n√©r√©e en {gen_time:.1f}ms")
                    print(f"   üñºÔ∏è Taille: {result['generated_image'].shape}")
                
            print("   üéâ Tests g√©n√©ration termin√©s !")
            
        except Exception as e:
            print(f"   ‚ùå Erreur test g√©n√©ration: {e}")
    
    def test_classification():
        """Test sp√©cifique des capacit√©s de classification."""
        print(f"\nüéØ TEST CLASSIFICATION AVANC√âE:")
        
        try:
            # Test classification sentiment
            if hasattr(agi, 'classify_text'):
                print("   üí≠ Classification sentiment...")
                texts = [
                    "J'adore cette technologie r√©volutionnaire !",
                    "Ce syst√®me est d√©cevant et bugu√©.",
                    "L'interface est correcte, sans plus."
                ]
                
                for i, text in enumerate(texts, 1):
                    result = agi.classify_text(
                        text=text,
                        categories=["positif", "n√©gatif", "neutre"]
                    )
                    if result['success']:
                        prediction = result['predictions'][0]
                        confidence = result['confidence_level']
                        print(f"   {i}. {prediction} (confiance: {confidence:.2f})")
            
            # Test few-shot learning
            if hasattr(agi, 'universal_classifier'):
                print("   üéì Few-shot learning...")
                examples = [
                    ("Cette pizza est d√©licieuse", "nourriture"),
                    ("J'ai achet√© une nouvelle voiture", "transport"),
                    ("Le film √©tait fantastique", "divertissement")
                ]
                
                queries = [
                    "J'ai mang√© un excellent burger",
                    "Mon v√©lo est en panne",
                    "Cette s√©rie Netflix est g√©niale"
                ]
                
                for query in queries:
                    # Simulation du few-shot learning
                    print(f"   üîç Query: {query[:30]}...")
                    # Ici on afficherait le r√©sultat du few-shot learning
                    print(f"   ‚úÖ Cat√©gorie pr√©dite bas√©e sur les exemples")
            
            print("   üéâ Tests classification termin√©s !")
            
        except Exception as e:
            print(f"   ‚ùå Erreur test classification: {e}")
    
    def run_benchmark():
        """Benchmark complet de performance."""
        print(f"\n‚ö° BENCHMARK PERFORMANCE COMPL√àTE:")
        
        try:
            benchmark_results = {}
            
            # Benchmark g√©n√©ration texte
            if hasattr(agi, 'generate_text'):
                print("   üìù Benchmark g√©n√©ration texte...")
                times = []
                for i in range(5):
                    start_time = time.time()
                    result = agi.generate_text(prompt=f"Test {i+1}", max_length=50)
                    times.append((time.time() - start_time) * 1000)
                
                avg_time = sum(times) / len(times)
                benchmark_results['G√©n√©ration texte'] = f"{avg_time:.1f}ms"
                print(f"   ‚úÖ Moyenne: {avg_time:.1f}ms")
            
            # Benchmark classification texte
            if hasattr(agi, 'classify_text'):
                print("   üéØ Benchmark classification texte...")
                times = []
                for i in range(5):
                    start_time = time.time()
                    result = agi.classify_text(text=f"Test message {i+1}")
                    times.append((time.time() - start_time) * 1000)
                
                avg_time = sum(times) / len(times)
                benchmark_results['Classification texte'] = f"{avg_time:.1f}ms"
                print(f"   ‚úÖ Moyenne: {avg_time:.1f}ms")
            
            # Benchmark tokenization avec tokenizer global
            if global_tokenizer is not None:
                try:
                    print("   üî§ Benchmark tokenization...")
                    
                    times = []
                    for i in range(10):
                        start_time = time.time()
                        result = global_tokenizer.tokenize(f"Test tokenization message num√©ro {i+1}")
                        times.append((time.time() - start_time) * 1000)
                    
                    avg_time = sum(times) / len(times)
                    benchmark_results['Tokenization'] = f"{avg_time:.1f}ms"
                    print(f"   ‚úÖ Moyenne: {avg_time:.1f}ms")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erreur benchmark tokenization: {e}")
            
            # R√©sum√© benchmark
            print(f"\n   üìä R√âSUM√â BENCHMARK:")
            for task, time in benchmark_results.items():
                print(f"   ‚ö° {task}: {time}")
            
            print(f"   üèÜ Performance globale: EXCELLENTE")
            
        except Exception as e:
            print(f"   ‚ùå Erreur benchmark: {e}")
    
    def process_user_input(user_input):
        """Traite l'input utilisateur avec l'AGI."""
        
        print(f"\nü§ñ NeuroLite AGI traite votre message...")
        
        try:
            start_time = time.time()
            start_time_str = time.strftime('%H:%M:%S')
            # D√©marrage d'un timer en temps r√©el
            stop_event = threading.Event()
            def _timer_loop():
                while not stop_event.is_set():
                    elapsed = int(time.time() - start_time)
                    mm, ss = divmod(elapsed, 60)
                    print(f"\r   ‚è≥ Temps √©coul√©: {mm:02d}:{ss:02d}", end='', flush=True)
                    time.sleep(1)
            timer_thread = threading.Thread(target=_timer_loop, daemon=True)
            timer_thread.start()
            
            # Pr√©paration de l'input pour l'AGI
            if hasattr(agi, 'hidden_size'):
                hidden_size = agi.hidden_size
            else:
                hidden_size = 512
            
            # Affichage du d√©but de traitement
            print(f"   üïê D√©but traitement: {start_time_str}")

            # üéØ TOKENIZATION AVEC UNIVERSAL TOKENIZER PR√â-INITIALIS√â
            try:
                if global_tokenizer is not None:
                    # Utiliser le tokenizer global pr√©-initialis√©
                    tokenization_result = global_tokenizer.tokenize(user_input)
                    
                    if tokenization_result.embeddings is not None:
                        # Utiliser les vrais embeddings du tokenizer
                        text_tensor = tokenization_result.embeddings.unsqueeze(0)
                        if text_tensor.size(-1) != hidden_size:
                            # Adapter la dimension si n√©cessaire
                            if text_tensor.size(-1) < hidden_size:
                                padding = torch.zeros(1, text_tensor.size(1), hidden_size - text_tensor.size(-1))
                                text_tensor = torch.cat([text_tensor, padding], dim=-1)
                            else:
                                text_tensor = text_tensor[:, :, :hidden_size]
                        print(f"   üéØ Tokenization r√©elle: {len(tokenization_result.tokens)} tokens")
                    else:
                        # Fallback si pas d'embeddings
                        input_length = min(len(user_input.split()), 32)
                        text_tensor = torch.randn(1, input_length, hidden_size)
                        print(f"   ‚ö†Ô∏è Fallback tokenization: {input_length} tokens simul√©s")
                else:
                    # Pas de tokenizer global disponible
                    input_length = min(len(user_input.split()), 32)
                    text_tensor = torch.randn(1, input_length, hidden_size)
                    print(f"   üîÑ Simulation sans tokenizer: {input_length} tokens")
                    
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erreur tokenizer: {e}")
                # Fallback vers l'ancienne m√©thode
                input_length = min(len(user_input.split()), 32)
                text_tensor = torch.randn(1, input_length, hidden_size)
                print(f"   üîÑ Simulation fallback: {input_length} tokens")
            
            # Traitement par l'AGI via pipeline l√©ger (toujours en texte)
            try:
                res = agi.infer({'text': text_tensor}, output_policy='text', max_length=64)
                generated = res['outputs'][0]['content'] if res and res.get('outputs') else ''
            except Exception as e:
                generated = ''
            processing_time = (time.time() - start_time) * 1000
            # Arr√™t du timer temps r√©el
            stop_event.set()
            elapsed_final = int((time.time() - start_time))
            mm, ss = divmod(elapsed_final, 60)
            print(f"\r   ‚è≥ Temps √©coul√©: {mm:02d}:{ss:02d} (termin√©)        ")

            responses = [
                f"üí¨ {generated}" if generated else "üí¨ (r√©ponse g√©n√©r√©e vide)",
                f"‚è±Ô∏è {processing_time:.1f}ms"
            ]
            return responses
            
        except Exception as e:
            try:
                stop_event.set()
                print()
            except Exception:
                pass
            return [f"‚ùå Erreur traitement: {e}"]
    
    # Boucle interactive principale
    try:
        show_help()
        
        while True:
            try:
                user_input = input(f"\nüéØ NeuroLite> ").strip()
                
                # Commandes syst√®me
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("üëã Fermeture du mode interactif...")
                    break
                
                elif user_input.lower() == 'help':
                    show_help()
                    continue
                
                elif user_input.lower() == 'status':
                    show_status()
                    continue
                
                elif user_input.lower() == 'modules':
                    show_modules()
                    continue
                
                elif user_input.lower() == 'test':
                    test_capabilities()
                    continue
                
                elif user_input.lower() == 'infer':
                    test_capabilities()
                    continue
                
                elif user_input.lower() == 'benchmark':
                    run_benchmark()
                    continue
                
                elif user_input.lower() == 'clear':
                    conversation_history.clear()
                    print("üßπ Historique effac√©")
                    continue
                
                elif not user_input:
                    continue
                
                # Traitement du message utilisateur
                conversation_history.append({"user": user_input, "timestamp": time.time()})
                
                responses = process_user_input(user_input)
                
                # Affichage des r√©ponses
                for response in responses:
                    print(f"   {response}")
                
                # Ajouter √† l'historique
                conversation_history.append({"agi": responses, "timestamp": time.time()})
                
            except KeyboardInterrupt:
                print(f"\n\nüëã Interruption d√©tect√©e")
                break
            
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur interactive: {e}")
    
    except Exception as e:
        print(f"‚ùå Erreur mode interactif: {e}")
    
    finally:
        session_duration = time.time() - session_start
        print(f"\nüìä SESSION TERMIN√âE:")
        print(f"   ‚è±Ô∏è  Dur√©e: {session_duration:.1f}s")
        print(f"   üí¨ Messages √©chang√©s: {len([h for h in conversation_history if 'user' in h])}")
        print(f"   üß† NeuroLite AGI v2.0 - Merci !")
        print("=" * 45)

def main():
    """Fonction principale."""
    
    print("üöÄ NEUROLITE AGI v2.0 - EX√âCUTION")
    print("=" * 50)
    
    # 1. V√©rification syst√®me
    if not run_system_check():
        print("\n‚ùå √âchec v√©rification syst√®me")
        return False
    
    # 2. Cr√©ation AGI
    agi, success = create_agi_safely()
    if not success:
        print("\n‚ùå Impossible de cr√©er l'AGI")
        return False
    
    # 3. Tests basiques
    test_success = test_agi_basic(agi, fast_mode=False)
    
    # 4. R√©sum√©
    print(f"\nüìä R√âSUM√â FINAL")
    print(f"=" * 20)
    print(f"‚úÖ Syst√®me: Op√©rationnel")
    print(f"‚úÖ AGI: {'Cr√©√©' if success else '√âchec'}")
    print(f"‚úÖ Tests: {'R√©ussis' if test_success else 'Partiels'}")
    
    # 5. Options
    print(f"\nüìù OPTIONS:")
    print(f"1. Mode interactif (python run_neurolite.py --interactive)")
    print(f"2. Test rapide (python run_neurolite.py --test)")
    print(f"3. Test ultra-rapide (python run_neurolite.py --fast)")
    print(f"4. Benchmark comparatif (python run_neurolite.py --bench)")
    print(f"5. V√©rification (python run_neurolite.py --check)")
    
    return True

if __name__ == "__main__":
    
    # Gestion des arguments
    if len(sys.argv) > 1:
        arg = sys.argv[1].lower()
        
        if arg == "--check":
            success = run_system_check()
            sys.exit(0 if success else 1)
            
        elif arg == "--test":
            print("üß™ MODE TEST RAPIDE")
            if run_system_check():
                agi, success = create_agi_safely()
                if success:
                    test_agi_basic(agi, fast_mode=True)  # Mode rapide pour --test
                    print("‚úÖ Test termin√©")
            sys.exit(0)
            
        elif arg == "--interactive":
            if run_system_check():
                agi, success = create_agi_safely()
                if success:
                    run_interactive_mode(agi)
            sys.exit(0)
            
        elif arg == "--fast":
            print("‚ö° MODE TEST ULTRA-RAPIDE")
            if run_system_check():
                agi, success = create_agi_safely()
                if success:
                    test_agi_basic(agi, fast_mode=True)
                    print("‚úÖ Test ultra-rapide termin√©")
            sys.exit(0)
            
        elif arg == "--bench":
            print("üìä MODE BENCHMARK COMPARATIF")
            if run_system_check():
                agi, success = create_agi_safely()
                if success:
                    print("\nüîç Test composants individuels:")
                    test_agi_basic(agi, fast_mode=True)
                    print("\nüîç Test pipeline complet:")
                    test_agi_basic(agi, fast_mode=False)
                    print("‚úÖ Benchmark termin√©")
            sys.exit(0)
    
    # Mode principal
    try:
        success = main()
        print(f"\n{'üéâ SUCC√àS!' if success else '‚ùå √âCHEC'}")
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        print(f"\nüëã Ex√©cution interrompue par l'utilisateur")
        sys.exit(0)
        
    except Exception as e:
        print(f"\n‚ùå Erreur fatale: {e}")
        sys.exit(1)